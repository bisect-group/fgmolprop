{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from rdkit.Chem import Descriptors, Draw\n",
    "from rdkit.Chem.rdmolfiles import MolFromSmarts, MolFromSmiles\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tokenizers import Tokenizer\n",
    "from torchmetrics.functional.clustering import davies_bouldin_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.data.components.utils import smiles2vector_fg, smiles2vector_mfg\n",
    "from src.models.fgr_module import FGRLitModule\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/processed\"\n",
    "fgroups = pd.read_parquet(os.path.join(data_dir, \"training\", \"fg.parquet\"))[\n",
    "    \"SMARTS\"\n",
    "].tolist()  # Get functional groups\n",
    "fgroups_list = [MolFromSmarts(x) for x in fgroups]  # Convert to RDKit Mol\n",
    "tokenizer = Tokenizer.from_file(\n",
    "    os.path.join(\n",
    "        data_dir,\n",
    "        \"training\",\n",
    "        \"tokenizers\",\n",
    "        f\"BPE_pubchem_{500}.json\",\n",
    "    )\n",
    ")  # Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(smi_list: List[str]) -> torch.Tensor:\n",
    "    \"\"\"Get descriptors from list of SMILES strings.\n",
    "\n",
    "    :param smi_list: List of SMILES strings\n",
    "    :return: Stacked descriptor tensor\n",
    "    \"\"\"\n",
    "    desc_tensors = []\n",
    "    for smi in smi_list:\n",
    "        mol = MolFromSmiles(smi)  # Get molecule from SMILES string\n",
    "\n",
    "        # Get descriptors\n",
    "        desc_list = []\n",
    "        for _, func in Descriptors._descList:\n",
    "            try:\n",
    "                desc_list.append(func(mol))\n",
    "            except BaseException:\n",
    "                desc_list.append(0)\n",
    "        descriptors = torch.FloatTensor(desc_list)\n",
    "        descriptors = torch.nan_to_num(\n",
    "            descriptors, nan=0.0, posinf=0.0, neginf=0.0\n",
    "        )  # Replace NaNs with 0\n",
    "        descriptors = descriptors / torch.norm(descriptors)  # Normalize\n",
    "\n",
    "        desc_tensors.append(descriptors)\n",
    "\n",
    "    return torch.stack(desc_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representation(\n",
    "    smiles: List[str],\n",
    "    method: str,\n",
    "    fgroups_list: List[MolFromSmarts],\n",
    "    tokenizer: Tokenizer,\n",
    "    dataset: str = \"BBBP\",\n",
    "    mode: str = \"train\",\n",
    ") -> np.ndarray:\n",
    "    if method == \"FG\":\n",
    "        x = np.stack([smiles2vector_fg(x, fgroups_list) for x in smiles])\n",
    "    elif method == \"MFG\":\n",
    "        x = np.stack([smiles2vector_mfg(x, tokenizer) for x in smiles])\n",
    "    elif method == \"FGR\":\n",
    "        f_g = np.stack([smiles2vector_fg(x, fgroups_list) for x in smiles])\n",
    "        mfg = np.stack([smiles2vector_mfg(x, tokenizer) for x in smiles])\n",
    "        x = np.concatenate((f_g, mfg), axis=1)  # Concatenate both vectors\n",
    "    else:\n",
    "        raise ValueError(\"Method not supported\")  # Raise error if method not supported\n",
    "    if mode == \"input\":\n",
    "        return x\n",
    "    elif mode == \"train\":\n",
    "        ckpt_path = glob.glob(\n",
    "            f\"./logs/train/multiruns/*/{dataset}/{method}/scaffold/*/checkpoints/last.ckpt\"\n",
    "        )[0]\n",
    "        model = FGRLitModule.load_from_checkpoint(ckpt_path)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32, device=model.device)\n",
    "            desc = get_descriptors(smiles).to(model.device)\n",
    "            x = model((x, desc))\n",
    "        return x[1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Mode not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaffolds(s: List[str]) -> Tuple[pd.DataFrame, LabelEncoder]:\n",
    "    scaffolds = defaultdict(set)\n",
    "    idx2mol = dict(zip(list(range(len(s))), s))\n",
    "    error_smiles = 0\n",
    "    for i, smiles in enumerate(s):\n",
    "        try:\n",
    "            scaffold = MurckoScaffold.MurckoScaffoldSmiles(\n",
    "                mol=MolFromSmiles(smiles), includeChirality=False\n",
    "            )\n",
    "            scaffolds[scaffold].add(i)\n",
    "        except BaseException:\n",
    "            print(smiles + \" returns RDKit error and is thus omitted...\")\n",
    "            error_smiles += 1\n",
    "\n",
    "    top_5_scaffolds = sorted(\n",
    "        ((k, v) for k, v in scaffolds.items() if k != \"\"),\n",
    "        key=lambda item: len(item[1]),\n",
    "        reverse=True,\n",
    "    )[:5]\n",
    "    data = [(idx2mol[idx], scaffold) for scaffold, indices in top_5_scaffolds for idx in indices]\n",
    "    scaffold_df = pd.DataFrame(data, columns=[\"SMILES\", \"Label\"])\n",
    "    label_encoder = LabelEncoder()\n",
    "    scaffold_df[\"Label\"] = label_encoder.fit_transform(scaffold_df[\"Label\"])\n",
    "    return scaffold_df, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaffolds(dataset_dir: str, label_encoder: LabelEncoder) -> None:\n",
    "    scaffold_dir = f\"{dataset_dir}/scaffolds\"\n",
    "    os.makedirs(scaffold_dir, exist_ok=True)\n",
    "    for i in range(5):\n",
    "        scaffold = label_encoder.inverse_transform([i])[0]\n",
    "        mol = MolFromSmiles(scaffold)\n",
    "        Draw.MolToFile(\n",
    "            mol,\n",
    "            f\"{scaffold_dir}/scaffold_{i}.svg\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_2d(method: str, components: np.ndarray, ax: mpl.axes._axes.Axes) -> None:  # type: ignore\n",
    "    sns.kdeplot(\n",
    "        x=components[:, 0],\n",
    "        y=components[:, 1],\n",
    "        cmap=\"rocket_r\",\n",
    "        fill=True,\n",
    "        levels=500,\n",
    "        bw_adjust=0.2,\n",
    "        cbar=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"Features\")\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_title(r\"$\\textbf{Method:}$\" f\"{method}\")\n",
    "\n",
    "\n",
    "def plot_kde(components: np.ndarray, ax: mpl.axes._axes.Axes) -> None:  # type: ignore\n",
    "    # Calculate the angles\n",
    "    angles = np.arctan2(components[:, 1], components[:, 0])\n",
    "    sns.kdeplot(x=angles, cmap=\"Blues\", fill=True, ax=ax)\n",
    "    ax.set_xlabel(\"Angles\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "def plot_tsne(\n",
    "    method: str,\n",
    "    dbi: float,\n",
    "    components: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    ax: mpl.axes._axes.Axes,  # type: ignore\n",
    ") -> None:\n",
    "    sns.scatterplot(\n",
    "        ax=ax,\n",
    "        x=components[:, 0],\n",
    "        y=components[:, 1],\n",
    "        hue=labels,\n",
    "        palette=sns.color_palette(\"colorblind\"),\n",
    "    )\n",
    "    ax.text(\n",
    "        0.95,\n",
    "        0.05,\n",
    "        r\"$\\textbf{DBI:}$\" f\"{dbi}\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=8,\n",
    "        bbox=dict(facecolor=\"grey\", alpha=0.2, edgecolor=\"black\"),\n",
    "    )\n",
    "    ax.get_legend().set_visible(False)\n",
    "    ax.set_title(r\"$\\textbf{Method:}$\" f\"{method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(\n",
    "    dataset: str, fgroups_list: List[MolFromSmarts], tokenizer: Tokenizer, mode: str\n",
    ") -> None:\n",
    "    methods = [\"FG\", \"MFG\", \"FGR\"]\n",
    "\n",
    "    df = pd.read_parquet(f\"./data/processed/tasks/{dataset}/{dataset}.parquet\")\n",
    "    s = df[\"SMILES\"].tolist()\n",
    "\n",
    "    dataset_dir = f\"./reports/figures/{dataset}\"\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    scaffold_df, label_encoder = get_scaffolds(s)\n",
    "    plot_scaffolds(dataset_dir, label_encoder)\n",
    "\n",
    "    tsne_fig, tsne_axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "    for i, method in enumerate(methods):\n",
    "        x = get_representation(\n",
    "            scaffold_df[\"SMILES\"].tolist(), method, fgroups_list, tokenizer, dataset, mode\n",
    "        )\n",
    "        components = TSNE(random_state=123).fit_transform(x)  # type: ignore\n",
    "        # Calculate DBI\n",
    "        dbi = round(\n",
    "            float(\n",
    "                davies_bouldin_score(\n",
    "                    torch.tensor(x), torch.tensor(scaffold_df[\"Label\"].to_numpy()).reshape(-1)\n",
    "                )\n",
    "            ),\n",
    "            2,\n",
    "        )\n",
    "        plot_tsne(method, dbi, components, scaffold_df[\"Label\"].to_numpy(), ax=tsne_axes[i])\n",
    "    tsne_fig.savefig(\n",
    "        f\"{dataset_dir}/{mode}_alignment.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "        transparent=True,\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    kde_fig, kde_axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    for i, method in enumerate(methods):\n",
    "        x = get_representation(s, method, fgroups_list, tokenizer)\n",
    "        components = TSNE(random_state=123).fit_transform(x)  # type: ignore\n",
    "        # Normalize the points to project them onto the unit circle\n",
    "        tsne_norm = components / np.linalg.norm(components, axis=1, keepdims=True)\n",
    "        plot_kde_2d(method, tsne_norm, ax=kde_axes[0, i])\n",
    "        plot_kde(tsne_norm, ax=kde_axes[1, i])\n",
    "    kde_fig.savefig(\n",
    "        f\"{dataset_dir}/{mode}_uniformity.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "        transparent=True,\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/processed/tasks/summary.parquet\")\n",
    "tasks = df[df[\"Datapoints\"] < 100000][\"Task\"].tolist()\n",
    "for task in tqdm(tasks):\n",
    "    plot_dataset(task, fgroups_list, tokenizer, \"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
